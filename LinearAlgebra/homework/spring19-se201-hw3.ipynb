{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "Due 3/29 11:59pm\n",
    "The homework must be uploaded to [LMS](https://lms.dgist.ac.kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "### 1-1.\n",
    "\n",
    "Find the projection of $b$ onto the column space of $A$:\n",
    "    $$A = \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\\\ -2 & 4 \\end{bmatrix},\\quad b=\\begin{bmatrix} 1\\\\ 2\\\\ 7\\end{bmatrix}$$\n",
    "\n",
    "### 1-2.\n",
    "\n",
    "Find the best straight-line fit (least square) to the measurements\n",
    "    $$(t,b) = (-2,4), (-1,3), (0,1), (2,0)$$\n",
    "for $C+Dt=b$ by using the projection of $b=(4,3,1,0)$ onto the column space of\n",
    "    $$A = \\begin{bmatrix} 1 & -2 \\\\ 1 & -1 \\\\ 1 & 0 \\\\ 1 & 2 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "### 2-1.\n",
    "\n",
    "Apply the Gram-Schmidt process to\n",
    "    $$a = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1\\end{bmatrix},\\quad b= \\begin{bmatrix}0 \\\\ 1\\\\ 1\\end{bmatrix},\\quad c =\\begin{bmatrix}1 \\\\ 1\\\\1\\end{bmatrix}$$\n",
    "and write the result in the form $A=QR$ where $Q$ is the matrix whose column vectors are orthonormal basis and $R$ is a upper-triangular matrix.\n",
    "\n",
    "### 2-2.\n",
    "\n",
    "Find an orthonormal set $q_1,q_2,q_3$ for which $q_1,q_2$ span the column space of\n",
    "    $$A = \\begin{bmatrix} 1 & 1 \\\\ 2 & -1 \\\\ -2 & 4\\end{bmatrix}$$\n",
    "and find the least-square solution of $Ax=\\begin{bmatrix}1 \\\\ 2\\\\ 7\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "The **rank** of a matrix $A$ if the number of pivots in the reduced row echelon form of $A$. It is also the dimension of the column space $C(A)$, which is the dimension of the row space $R(A)$. The fact that the dimension of $C(A)$ and $R(A)$ are equal is very important, and it is not at all obvious. We will discuss more detail throughout this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1.\n",
    "\n",
    "Let $A$ be a $n\\times m$ matrix and $R$ be the reduced row echelon form of $A$. Let $v_1,\\cdots,v_m$ be the column vectors of $A$ and $w_1,\\cdots,w_m$ be the column vectors of $R$.\n",
    "    $$A = \\begin{bmatrix} v_1 & \\cdots & v_m \\end{bmatrix},\\quad R = \\begin{bmatrix} w_1 & \\cdots & w_m \\end{bmatrix}$$\n",
    "Show that a set of vectors $v_{j_1},\\cdots,v_{j_s}$ is linearly independent (with respectively, dependent) if and only if the set of vectors $w_{j_1},\\cdots,w_{j_s}$ is linear independent (or dependent).\n",
    "\n",
    "**Caution**: The set $v_{j_1},\\cdots,v_{j_s}$ is a subset of the set of column vectors $v_1,\\cdots,v_m$ ($s\\le m$). Also, the indices of $v_{j_1},\\cdots,v_{j_s}$ and $w_{j_1},\\cdots,w_{j_s}$ coincide, and this is the main focus of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2.\n",
    "\n",
    "Show that the dimension of $R(A)$ is equal to the number of pivots in $R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion (read and think)\n",
    "\n",
    "Let us show that $\\dim C(A) = \\dim R(A)$. Let $R$ be the reduced row echelon form of $A$ and $r$ be the number of pivots in $R$. \n",
    "\n",
    "Let us show that $r=\\dim C(A)$. Let $j_1,\\cdots,j_r$ be the columns of pivots. By problem 3-1, the set of column vectors $v_{j_1},\\cdots, v_{j_r}$ is linearly independent. Moreover, we show that any column vector $v_k$ of $A$ is written as linear combination of $v_{j_1},\\cdots, v_{j_r}$. If $v_k$ is one of $v_{j_1},\\cdots, v_{j_r}$, it is a linear combination of itself. If not, the set $v_k,v_{j_1},\\cdots,v_{j_r}$ is linearly dependent because the corresponding set $w_k,w_{j_1},\\cdots,w_{j_r}$ (column vectors in $R$) is linearly dependent. (The set $w_{j_1},\\cdots,w_{j_r}$ forms a canonical basis of $C(W)$.) By problem 3-1, the set $v_k,v_{j_1},\\cdots,v_{j_r}$ is also linearly dependent. That is, there are coefficients $c_k,c_{j_1},\\cdots,c_{j_r}$, which are not all zero, satisfying \n",
    "    $$c_kv_k + c_{j_1}v_{j_1} + \\cdots + c_{j_r}v_{j_r} = 0.$$\n",
    "Here, $c_k\\neq0$ because $v_{j_1},\\cdots, v_{j_r}$ is linearly independent. Thus $v_k$ can be written as linear combination of $v_{j_1},\\cdots, v_{j_r}$.\n",
    "\n",
    "By problem 3-2, we know that $r=\\dim R(A)$. Thus we can conclude that $\\dim C(A) = \\dim R(A)$.\n",
    "\n",
    "### Remark\n",
    "\n",
    "Later, the **rank** plays crucial role in determine whether the matrix is nonsingular. If a $n\\times n$ matrix $A$ has rank less than $n$, then $A$ is singular, that is $A$ has no inverse. If the matrix $A$ is of rank $n$, in other words *full rank*, then $A$ has its inverse. Moreover, a full rank matrix has nonzero determinant, and vice versa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
