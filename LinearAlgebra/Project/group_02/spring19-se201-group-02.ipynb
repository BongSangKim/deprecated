{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "\n",
    "* 오바마와 트럼프의 대통령 연설문 학습을 통해 두 사람간의 특정 정치 문제에 대한 인식 비교\n",
    "* 중심단어 찾기\n",
    "* 어떤 결론을 예상하는지, 방법 구상."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224679, 308100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim.utils\n",
    "\n",
    "text = []\n",
    "for ind in range(2):\n",
    "    indstr = str(ind)\n",
    "    filename = \"ob_\" + str(indstr.zfill(2)) + \".txt\"\n",
    "    with open(filename) as file:\n",
    "        line = file.readline()\n",
    "        while line:\n",
    "            text.append(gensim.utils.simple_preprocess(line))\n",
    "            line = file.readline()\n",
    "\n",
    "ob = Word2Vec(text, size=10, window=5, min_count=1, workers=4)\n",
    "ob.train(text, total_examples=len(text), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5137342   0.6598243  -2.5572336  -0.37080902  2.2349133  -0.35990852\n",
      "  0.30606326  1.2491828   1.7751232  -0.7272541 ]\n"
     ]
    }
   ],
   "source": [
    "print(ob.wv['war'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('counties', 0.9390755891799927),\n",
       " ('expect', 0.9264619946479797),\n",
       " ('wrong', 0.9243521690368652),\n",
       " ('parks', 0.9213158488273621),\n",
       " ('collar', 0.9179496765136719),\n",
       " ('into', 0.9161678552627563),\n",
       " ('government', 0.9031386971473694),\n",
       " ('agents', 0.891487181186676),\n",
       " ('pledging', 0.8849846124649048),\n",
       " ('dissent', 0.8846445679664612)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob.wv.most_similar(positive='people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345428, 465100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim.utils\n",
    "\n",
    "text = []\n",
    "for ind in range(2):\n",
    "    indstr = str(ind)\n",
    "    filename = \"dt_\" + str(indstr.zfill(2)) + \".txt\"\n",
    "    with open(filename) as file:\n",
    "        line = file.readline()\n",
    "        while line:\n",
    "            text.append(gensim.utils.simple_preprocess(line))\n",
    "            line = file.readline()\n",
    "\n",
    "dt = Word2Vec(text, size=10, window=5, min_count=1, workers=4)\n",
    "dt.train(text, total_examples=len(text), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4882315  -0.7992657   0.40448263 -0.13521193  1.0974772  -0.5537114\n",
      " -0.46462747 -0.8319872   1.6323336   0.12403236]\n"
     ]
    }
   ],
   "source": [
    "print(dt.wv['war'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('middle', 0.929962158203125),\n",
       " ('reclaim', 0.9265064597129822),\n",
       " ('rightly', 0.9256851673126221),\n",
       " ('homes', 0.9251159429550171),\n",
       " ('struggle', 0.9215483665466309),\n",
       " ('outraged', 0.9179838299751282),\n",
       " ('they', 0.9028629660606384),\n",
       " ('east', 0.8976569771766663),\n",
       " ('futures', 0.8967217803001404),\n",
       " ('gates', 0.8892354965209961)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.wv.most_similar(positive='people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from os import walk\n",
    "\n",
    "file_list = []\n",
    "current_path = \"./black and white/Obama/\"\n",
    "for (dirpath, dirnames, filenames) in walk(current_path):\n",
    "    file_list.extend(filenames)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(current_path, file_list):\n",
    "    for i in range(len(file_list)):\n",
    "        with open(current_path + file_list[i]) as file:\n",
    "            for j, line in enumerate(file):\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "\n",
    "document = list(read_input(current_path, file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14019161, 19320100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob_model = gensim.models.Word2Vec (document, size=50, window=10, min_count=2, workers=4)\n",
    "ob_model.train(document, total_examples=len(document), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27670728, 38791500)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = []\n",
    "current_path = \"./black and white/Trump/\"\n",
    "for (dirpath, dirnames, filenames) in walk(current_path):\n",
    "    file_list.extend(filenames)\n",
    "    break\n",
    "\n",
    "document = list(read_input(current_path, file_list))\n",
    "\n",
    "tp_model = gensim.models.Word2Vec (document, size=50, window=10, min_count=2, workers=4)\n",
    "tp_model.train(document, total_examples=len(document), epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628\n"
     ]
    }
   ],
   "source": [
    "print(ob_model.wv.vocab['america'].count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n"
     ]
    }
   ],
   "source": [
    "print(tp_model.wv.vocab['america'].count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.7022676  -1.6674688   3.0069063  -5.3478923  -1.9331398  -0.25422457\n",
      " -0.25690597 -0.00859228 -0.42265344  3.3374572   1.6910458   2.088745\n",
      "  1.1570014  -3.1609087  -0.6632904  -1.5752858   0.31854093  3.7764752\n",
      "  1.665927    4.017706   -0.32409427 -3.677158    0.7400888  -0.72380555\n",
      " -1.297111    3.8206308   0.44168893  0.39383295  0.73985165 -1.993766\n",
      " -0.80594677  1.6543396  -0.8799783  -1.0457944   2.6614423  -3.0394385\n",
      "  3.1157656  -1.0311085   1.2337657  -3.2467515   2.5376484  -3.4149659\n",
      " -0.5187394   1.2119871   0.13813296  0.07816386 -3.0467827  -2.337552\n",
      " -4.166147   -2.6289208 ]\n"
     ]
    }
   ],
   "source": [
    "print(ob_model.wv['america'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('interests', 0.4738289713859558),\n",
       " ('america', 0.4508238434791565),\n",
       " ('learned', 0.4103170335292816),\n",
       " ('our', 0.40913844108581543),\n",
       " ('culture', 0.4091084897518158),\n",
       " ('sadly', 0.4007113575935364),\n",
       " ('doctors', 0.3974442481994629),\n",
       " ('fourthly', 0.37827572226524353),\n",
       " ('yourself', 0.37610721588134766),\n",
       " ('stealing', 0.37465566396713257),\n",
       " ('its', 0.3706246614456177),\n",
       " ('their', 0.3685663342475891),\n",
       " ('shootings', 0.3664732575416565),\n",
       " ('flourish', 0.36581212282180786),\n",
       " ('fear', 0.36036866903305054),\n",
       " ('us', 0.35819631814956665),\n",
       " ('brighter', 0.35814493894577026),\n",
       " ('these', 0.35157835483551025),\n",
       " ('depleted', 0.3510563373565674),\n",
       " ('revolution', 0.3472731411457062)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_model.wv.most_similar(positive = ['american'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('culture', 0.5157926082611084),\n",
       " ('attempt', 0.48253700137138367),\n",
       " ('borders', 0.47929853200912476),\n",
       " ('american', 0.4738289713859558),\n",
       " ('restraints', 0.4692506790161133),\n",
       " ('citizens', 0.46234965324401855),\n",
       " ('proper', 0.4561076760292053),\n",
       " ('dean', 0.4560396075248718),\n",
       " ('values', 0.45519810914993286),\n",
       " ('challenge', 0.4438784122467041),\n",
       " ('impose', 0.440816730260849),\n",
       " ('timeless', 0.43931639194488525),\n",
       " ('honoring', 0.43709123134613037),\n",
       " ('principal', 0.43662887811660767),\n",
       " ('defend', 0.43469947576522827),\n",
       " ('cause', 0.43136268854141235),\n",
       " ('homeland', 0.41546183824539185),\n",
       " ('heritage', 0.4153389036655426),\n",
       " ('side', 0.4085782766342163),\n",
       " ('threats', 0.4074656367301941)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_model.wv.most_similar(positive = ['interests'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47382903"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "v1 = tp_model.wv['american']\n",
    "v2 = tp_model.wv['interests']\n",
    "np.dot(v1, v2) /(np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('okay', 0.4834681749343872),\n",
       " ('sununu', 0.4182129204273224),\n",
       " ('horrible', 0.3948129415512085),\n",
       " ('chris', 0.3865438997745514),\n",
       " ('divided', 0.38327211141586304),\n",
       " ('rebuilt', 0.3705732524394989),\n",
       " ('leadership', 0.36900073289871216),\n",
       " ('much', 0.3621877133846283),\n",
       " ('tougher', 0.36034923791885376),\n",
       " ('big', 0.3560989499092102),\n",
       " ('well', 0.35070931911468506),\n",
       " ('european', 0.34446269273757935),\n",
       " ('abusers', 0.3439093828201294),\n",
       " ('stupidly', 0.34343791007995605),\n",
       " ('china', 0.34287309646606445),\n",
       " ('immediately', 0.3347597122192383),\n",
       " ('remind', 0.3329356014728546),\n",
       " ('cars', 0.332592248916626),\n",
       " ('before', 0.33145463466644287),\n",
       " ('with', 0.33046284317970276)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_model.wv.most_similar(negative = ['american'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3428731"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = tp_model.wv['american']\n",
    "v2 = tp_model.wv['china']\n",
    "np.dot(v1, v2) /(np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 9366\n",
      "and 7050\n",
      "to 6586\n",
      "of 5394\n",
      "that 5109\n",
      "we 4089\n",
      "in 3332\n",
      "our 2613\n",
      "is 2145\n",
      "for 2063\n",
      "it 2028\n",
      "this 1604\n",
      "you 1400\n",
      "have 1359\n",
      "are 1345\n",
      "on 1324\n",
      "will 1282\n",
      "applause 1271\n",
      "as 1154\n",
      "not 1153\n",
      "but 1121\n",
      "be 1102\n",
      "with 1089\n",
      "they 1033\n",
      "who 1020\n",
      "can 988\n",
      "people 893\n",
      "more 890\n",
      "their 872\n",
      "so 834\n",
      "what 812\n",
      "or 799\n",
      "by 755\n",
      "from 754\n",
      "all 716\n",
      "us 671\n",
      "ve 668\n",
      "do 645\n",
      "america 628\n",
      "has 616\n",
      "now 601\n",
      "at 580\n",
      "there 573\n",
      "an 553\n",
      "if 543\n",
      "just 538\n",
      "was 529\n",
      "re 528\n",
      "because 526\n",
      "those 518\n",
      "about 513\n",
      "when 512\n",
      "one 491\n",
      "new 481\n",
      "here 473\n",
      "make 472\n",
      "these 472\n",
      "world 452\n",
      "american 440\n",
      "than 440\n",
      "time 439\n",
      "know 438\n",
      "years 425\n",
      "some 406\n",
      "work 401\n",
      "them 396\n",
      "up 389\n",
      "been 388\n",
      "my 387\n",
      "no 381\n",
      "country 378\n",
      "every 375\n",
      "out 358\n",
      "like 351\n",
      "want 350\n",
      "right 350\n",
      "americans 346\n",
      "your 339\n",
      "how 331\n",
      "get 330\n",
      "would 323\n",
      "over 322\n",
      "must 321\n",
      "going 315\n",
      "jobs 310\n",
      "let 304\n",
      "economy 303\n",
      "also 298\n",
      "why 298\n",
      "need 296\n",
      "where 295\n",
      "should 295\n",
      "think 281\n",
      "don 278\n",
      "states 275\n",
      "president 273\n",
      "year 273\n",
      "were 270\n",
      "he 265\n",
      "me 265\n"
     ]
    }
   ],
   "source": [
    "wordlist = []\n",
    "count = []\n",
    "for word, obj in ob_model.wv.vocab.items():\n",
    "    wordlist.append(word)\n",
    "    count.append(obj.count)\n",
    "for _ in range(100):\n",
    "    idx = count.index(max(count))\n",
    "    print(wordlist[idx], max(count))\n",
    "    del count[idx]\n",
    "    del wordlist[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
